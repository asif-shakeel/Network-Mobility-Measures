#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
timeElapsed_flows_h3.py
======================

Time-Elapsed Flow Diagnostics on an H3 Mobility Network
-------------------------------------------------------

This script analyzes *synthetic origin–destination flows* generated by
`pep_generator_h3.py` and computes **time-elapsed, net, and mean flows**
over an H3-based mobility network.

It operates on:

    • pep_od.csv   (aggregated synthetic OD flows per time bin)
    • corridor/grid manifest from graph_builder_h3.py

and produces **flow-based diagnostics and interactive maps** that reveal:

    • net directional flows over a time span
    • mean inward vs outward edge flows (δT = +1 / −1)
    • hub-to-hub metro flows
    • node accumulation (in − out)
    • optional background adjacency structure

This is a *post-simulation analysis tool* — it does not generate mobility,
but rather measures how mass propagates through the synthetic network
over time.


----------------------------------------------------------------------
INPUTS
----------------------------------------------------------------------

From pep_generator_h3.py:

    csvs/pep_od.csv
        start_h3, end_h3, date, time,
        trip_count,
        mean_length_m, median_length_m, std_length_m,
        mean_travel_time_min, median_travel_time_min, std_travel_time_min

From graph_builder_h3.py:

    corridors_manifest_*.json   (or grid_manifest_*.json)

The manifest supplies:

    • node coordinates
    • hub identities
    • overlay vs background edges
    • metro edges (hub ↔ hub)
    • directional labels (delta_T)


----------------------------------------------------------------------
CORE COMPUTATIONS
----------------------------------------------------------------------

For a time span [t₁, t₂]:

1) Build per-bin flow matrices:

       F(b)[i,j] = trips from j → i in time bin b

2) Normalize to Markov kernels:

       M(b) = column-stochastic(F(b))

3) Compute elapsed flow operator:

       C = M(b₂) · ... · M(b₁) · F(b₁)

   where C[i,j] is the expected number of agents that started at j
   and ended at i over the full span.

4) From C:

    • Net flows:
          C_net = max(C − Cᵀ, 0)

    • Mean edge flows:
          meanF = (1/B) Σ_b F(b)

    • Mean node accumulation:
          ⟨in − out⟩ per node


----------------------------------------------------------------------
OUTPUTS
----------------------------------------------------------------------

All results are written to:

    outputs/runs/.../timeElapsed_flows/

Files and maps:

    netflows_map_*.html
        Time-elapsed net directional flows

    meanflow_inward_*.html
        Mean edge flows on edges with δT = +1 or 0

    meanflow_outward_*.html
        Mean edge flows on edges with δT = −1 or 0

    mean_inward_edges.csv
    mean_outward_edges.csv
        Tabular versions of the mean edge flows

Optional overlays:

    • hub nodes
    • metro (hub↔hub) edges
    • node intensity (start mass)
    • node accumulation (mean in − out)

All maps include:

    • layer toggles
    • stacked legends
    • directional arrows
    • consistent color scaling


----------------------------------------------------------------------
DESIGN PHILOSOPHY
----------------------------------------------------------------------

This tool measures *how mobility propagates through a network over time*.

It is not a traffic assignment or route model — it is a **flow diagnostic
layer** for Markov mobility systems, designed to reveal:

    • dominant corridors
    • directional asymmetries
    • hub influence
    • spatial accumulation
    • structural bias from overlay geometry


----------------------------------------------------------------------
AUTHOR
----------------------------------------------------------------------

Asif Shakeel  
email: ashakeel@ucsd.edu
"""


import os, json
from dataclasses import dataclass
from typing import Optional, Tuple, Dict, List

import numpy as np
import pandas as pd
from scipy import sparse

try:
    import folium
    import branca.colormap as cmb
    HAS_FOLIUM = True
except Exception:
    HAS_FOLIUM = False

# === H3 API ===
import h3.api.basic_str as h3s


# =========================
# CONFIG
# =========================
BASE_DIR = "/Users/asif/Documents/nm24/outputs"
RUN_DIR  = os.path.join(BASE_DIR, "runs")
COUNTRY     = "USA" # "Mexico"
REGION_NAME = "Atlanta, Georgia" # "Mexico City, Mexico"
H3_RES = 6

GRAPH_MODE =    "corridors"  # "corridors" | "grid"
NEIGHBOR_TOPOLOGY = "6"
FEEDER_MODE = "single"
EDGE_DIRECTION_MODE = "potential"
INCLUDE_BACKGROUND_EDGES = False
INIT_X_MODE = "periodic_fixed_point"    #   "periodic_fixed_point"   # or "flat"

TIME_RES_MIN = 30
SPAN_START   = "2025-06-01 06:00:00"
SPAN_END     = "2025-06-01 12:00:00"
PEP_SPAN_START   = "2025-06-01 00:00:00"
PEP_SPAN_END     = "2025-06-30 00:00:00"

NETFLOWS_PERCENTILE = 0.75
MIN_COUNT = 1.0
DROP_DIAGONAL = True

RUN_MEAN_EDGE_IN_OUT = True
MEAN_EDGE_PERCENTILE  = 0.00
MEAN_NEUTRAL_TOL      = 1e-9
RUN_MEAN_EDGE_NETFLOW = True
RUN_MEAN_NODE_ACCUM = True

MAKE_MAPS = True


FOLIUM_TILES = "cartodbpositron"
SHOW_ALL_CELLS = True
ALL_CELLS_MARKER_RADIUS = 2.5
ALL_CELLS_MARKER_OPACITY = 0.9
ARROW_MIN_LEN_M = 300.0
ARROW_MAX_LEN_M = 1200.0
ARROW_FRAC_OF_SEG = 0.50
ARROW_TIP_ANGLE   = 28.0
RUN_NETFLOWS = True
SHOW_NODE_INTENSITY = False
SHOW_METRO_EDGES = False

START_COL = "start_h3"
END_COL   = "end_h3"
DATE_COL  = "date"
TIME_COL  = "time"

# --- Tags / paths ---
def _city_tag(): return (REGION_NAME.split(',')[0]).replace(' ', '') or "Region"
def _top_tag(): return f"h3res-{NEIGHBOR_TOPOLOGY}"
def _fdr_tag(): return f"fdr-{FEEDER_MODE}"
def _edge_tag():
    # direction labeling: "potential" or "geometric"
    if EDGE_DIRECTION_MODE == "potential":
        return "edge-pot"
    elif EDGE_DIRECTION_MODE == "geometric":
        return "edge-geom"
    else:
        return f"edge-{EDGE_DIRECTION_MODE}"
def _overlay_tag(): return "ovr-1" if INCLUDE_BACKGROUND_EDGES else "ovr-0"

city_tag = _city_tag(); top_tag = _top_tag(); fdr_tag = _fdr_tag()
edge_tag = _edge_tag(); overlay_tag = _overlay_tag()

if GRAPH_MODE == "corridors":
   CORRIDOR_MANIFEST_FILENAME = f"corridors_manifest_{city_tag}_mode-h3_{fdr_tag}_{edge_tag}_{overlay_tag}.json"
else:
     CORRIDOR_MANIFEST_FILENAME = f"grid_manifest_{city_tag}_mode-h3.json"

CORRIDOR_MANIFEST_PATH = os.path.join(BASE_DIR, "corridors_outputs_h3", CORRIDOR_MANIFEST_FILENAME)

PEP_SPAN_START_TS = pd.to_datetime(PEP_SPAN_START)
PEP_SPAN_END_TS   = pd.to_datetime(PEP_SPAN_END)
start_tag = PEP_SPAN_START_TS.strftime("%Y%m%dT%H%M")
end_tag   = PEP_SPAN_END_TS.strftime("%Y%m%dT%H%M")

if GRAPH_MODE == "corridors":
    RUN_NAME = (
        f"{city_tag}/h3res-{H3_RES}/graph-{GRAPH_MODE}/{fdr_tag}/{edge_tag}/{overlay_tag}/"
        f"{start_tag}_{end_tag}/m{TIME_RES_MIN}/x-{INIT_X_MODE}"
    )
else:
    RUN_NAME = (
        f"{city_tag}/h3res-{H3_RES}/graph-{GRAPH_MODE}/"
        f"{start_tag}_{end_tag}/m{TIME_RES_MIN}/x-{INIT_X_MODE}"
    )

DATA_DIR   = os.path.join(RUN_DIR, RUN_NAME, "csvs")
OUTPUT_DIR = os.path.join(RUN_DIR, RUN_NAME, "timeElapsed_flows")
os.makedirs(OUTPUT_DIR, exist_ok=True)
OD_INPUT_PATH = os.path.join(DATA_DIR, "pep_od.csv")


# =========================
# Manifest loading
# =========================
def _load_manifest(path: str):
    print(f"MANIFEST PATH : {path}")
    if not os.path.exists(path):
        print(f"[MANIFEST] Not found: {path}")
        return {}, [], []
    try:
        with open(path, "r", encoding="utf-8") as f:
            doc = json.load(f)
    except Exception as e:
        print(f"[MANIFEST] Error reading manifest: {e}")
        return {}, [], []

    nodes = {}
    for h, meta in doc.get("nodes", {}).items():
        try:
            lat = float(meta["lat"]); lon = float(meta["lon"])
            nodes[str(h).lower()] = (lat, lon)
        except Exception:
            continue

    hubs = []
    hubs_obj = doc.get("hubs", {}).get("h3", {})
    if isinstance(hubs_obj, dict):
        hubs = [str(k).lower() for k in hubs_obj.keys()]
    elif isinstance(doc.get("hubs"), list):
        hubs = [str(k).lower() for k in doc["hubs"]]
    print(f"[MANIFEST] Loaded {len(nodes)} node coords, {len(hubs)} hubs")

    metro_edges = []
    edges_obj = doc.get("edges", {}).get("AM", [])
    for rec in edges_obj:
        if int(rec.get("is_metro", 0)) != 1:
            continue
        try:
            s = str(rec["start_h3"]).lower()
            d = str(rec["end_h3"]).lower()
            metro_edges.append((s, d))
        except Exception:
            continue
    print(f"[MANIFEST] Loaded {len(metro_edges)} metro edges")
    # Extract non-metro regular edges with overlay_flag/background_flag
    overlay_edges = set()
    background_edges = set()
    for rec in edges_obj:
        try:
            s = str(rec.get("start_h3")).lower()
            d = str(rec.get("end_h3")).lower()
            if int(rec.get("is_metro", 0)) == 1:
                continue
            if int(rec.get("overlay_flag", 0)) == 1:
                overlay_edges.add((s, d))
            else:
                background_edges.add((s, d))
        except Exception:
            continue

    return nodes, hubs, metro_edges, overlay_edges, background_edges


(MANIFEST_NODES,
 MANIFEST_HUBS,
 MANIFEST_METRO_EDGES,
 MANIFEST_OVERLAY,
 MANIFEST_BACKGROUND) = _load_manifest(CORRIDOR_MANIFEST_PATH)


# =========================
# H3 coordinate helpers
# =========================
def h3_to_latlon(hidx: str) -> Tuple[float, float]:
    try:
        return h3s.cell_to_latlng(hidx)
    except Exception:
        return (0.0, 0.0)

def resolve_latlon(hidx: str) -> Tuple[float, float]:
    key = str(hidx).strip().lower()
    return MANIFEST_NODES.get(key, h3_to_latlon(key))


# =========================
# Per-bin structure
# =========================
@dataclass
class PerBin:
    bin_start: pd.Timestamp
    F: sparse.csr_matrix
    M: sparse.csr_matrix

def ensure_bin_start(df, res_min):
    d = df.copy()
    if "trip_count" not in d.columns and "count" in d.columns:
        d = d.rename(columns={"count": "trip_count"})
    d["trip_count"] = pd.to_numeric(d["trip_count"], errors="coerce").fillna(0).astype(int)
    d[START_COL] = d[START_COL].astype(str).str.lower().str.strip()
    d[END_COL] = d[END_COL].astype(str).str.lower().str.strip()
    combo = d[DATE_COL].astype(str) + " " + d[TIME_COL].astype(str)
    dt = pd.to_datetime(combo, format="%Y%m%d %H:%M:%S", errors="coerce")
    d["bin_start"] = dt
    d["bin_end"] = dt + pd.to_timedelta(res_min, unit="m")
    return d

def crop_to_span_STRICT(df, span_start, span_end, res_min):
    d = ensure_bin_start(df, res_min)
    t1 = pd.to_datetime(span_start)
    t2 = pd.to_datetime(span_end)
    last_needed_start = t2 - pd.to_timedelta(res_min, unit="m")
    return d[(d["bin_start"] >= t1) & (d["bin_start"] <= last_needed_start)].copy()

def build_per_bin(df):
    cells = pd.Index(sorted(pd.unique(pd.concat([df[START_COL], df[END_COL]], ignore_index=True))))
    idx = {h: i for i, h in enumerate(cells)}
    N = len(cells)
    out = []
    for t, g in df.groupby("bin_start", sort=True):
        rows = g[END_COL].map(idx).to_numpy()
        cols = g[START_COL].map(idx).to_numpy()
        data = g["trip_count"].to_numpy(dtype=np.int64)
        F = sparse.csr_matrix((data, (rows, cols)), shape=(N, N))
        colsum = np.asarray(F.sum(axis=0)).ravel()
        inv = np.zeros_like(colsum, dtype=float)
        nz = colsum > 0
        inv[nz] = 1.0 / colsum[nz]
        M = F @ sparse.diags(inv)
        out.append(PerBin(bin_start=pd.Timestamp(t), F=F.tocsr(), M=M.tocsr()))
    return out, cells


# =========================
# Flow computations
# =========================
def legacy_elapsed_counts(per_bin, i1, i2_excl):
    N = per_bin[0].F.shape[0]
    A = sparse.identity(N, format="csr")
    for t in range(i1, i2_excl):
        A = per_bin[t].M @ A
    F1 = per_bin[i1].F
    n_start = np.asarray(F1.sum(axis=0)).ravel().astype(float)
    C = A.toarray() * n_start[np.newaxis, :]
    return C

def locate_span(per_bin, span_start, span_end, res_min):
    t1 = pd.to_datetime(span_start)
    t2 = pd.to_datetime(span_end)
    t_last = t2 - pd.to_timedelta(res_min, unit="m")
    index = {pb.bin_start: i for i, pb in enumerate(per_bin)}
    if t1 not in index or t_last not in index:
        raise ValueError("Span edges not present in bins.")
    return index[t1], index[t_last] + 1, t1, t2

def counts_to_edges(C, cells, percentile, min_count):
    ii, jj = np.nonzero(C)
    if ii.size == 0:
        return pd.DataFrame()
    vals = C[ii, jj].astype(float)
    thr = np.quantile(vals, percentile) if (percentile > 0 and vals.size) else 0.0
    keep = (vals >= max(thr, min_count))
    ii, jj, vals = ii[keep], jj[keep], vals[keep]
    df = pd.DataFrame({"i": ii, "j": jj, "count": vals})
    df["src_h3"] = cells[df["j"].values]
    df["dst_h3"] = cells[df["i"].values]
    src = np.array([resolve_latlon(h) for h in df["src_h3"]])
    dst = np.array([resolve_latlon(h) for h in df["dst_h3"]])
    df["src_lat"], df["src_lon"] = src[:,0], src[:,1]
    df["dst_lat"], df["dst_lon"] = dst[:,0], dst[:,1]
    df["count_disp"] = np.round(df["count"]).astype(int)
    df.sort_values("count", ascending=False, inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df


# =========================
# Folium helpers & map export
# =========================
def _mercator_xy(lat, lon, R=6378137.0):
    from math import log, tan, pi, radians
    x = R * radians(lon)
    lat = max(min(lat, 85.05112878), -85.05112878)
    y = R * log(tan(pi / 4.0 + radians(lat) / 2.0))
    return x, y

def _mercator_inv(x, y, R=6378137.0):
    from math import atan, sinh, degrees
    lat = degrees(atan(sinh(y / R)))
    lon = degrees(x / R)
    return lat, lon

def _arrow_triangle(lat1, lon1, lat2, lon2,
                    min_len_m=ARROW_MIN_LEN_M,
                    max_len_m=ARROW_MAX_LEN_M,
                    frac_of_seg=ARROW_FRAC_OF_SEG,
                    tip_angle_deg=ARROW_TIP_ANGLE):
    from math import radians, tan
    x1, y1 = _mercator_xy(lat1, lon1)
    x2, y2 = _mercator_xy(lat2, lon2)
    vx, vy = x2 - x1, y2 - y1
    seg = (vx * vx + vy * vy) ** 0.5
    if seg < 1e-6:
        return None
    L = max(min_len_m, min(max_len_m, seg * frac_of_seg))
    ux, uy = vx / seg, vy / seg
    bx, by = x2 - L * ux, y2 - L * uy
    px, py = -uy, ux
    half_base = L * tan(radians(tip_angle_deg) / 2.0)
    leftx, lefty = bx + half_base * px, by + half_base * py
    rightx, righty = bx - half_base * px, by - half_base * py
    tip = _mercator_inv(x2, y2)
    left = _mercator_inv(leftx, lefty)
    right = _mercator_inv(rightx, righty)
    return [tip, left, right]

# ----------------------------
# Title + stacked legends (safe)
# ----------------------------
from branca.element import MacroElement, Template
import html as _html  # avoid clobbering your "html" module name

def add_title(m, text: str, *, top_px=10):
    """
    Small fixed title banner at top-center.
    Uses LOW z-index so it never hides Leaflet controls.
    """
    safe = _html.escape("" if text is None else str(text))
    m.get_root().html.add_child(
        folium.Element(
            f"""
            <div style="
                position: absolute;
                top: {int(top_px)}px;
                left: 50%;
                transform: translateX(-50%);
                z-index: 450;              /* < Leaflet controls */
                background: rgba(255,255,255,.92);
                padding: 6px 10px;
                border-radius: 8px;
                box-shadow: 0 1px 6px rgba(0,0,0,.15);
                font-family: sans-serif;
                font-size: 13px;
                font-weight: 700;
                color: #222;
                pointer-events: none;      /* never blocks LayerControl */
                max-width: 70%;
                white-space: nowrap;
                overflow: hidden;
                text-overflow: ellipsis;
            ">
                {safe}
            </div>
            """
        )
    )

def add_stacked_legends(
    m,
    legend_html_blocks,
    *,
    position="bottomright",
    inset_x_px=80,     # horizontal shift toward center
    inset_y_px=140,    # vertical shift upward
    max_width_px=240,
    gap_px=8,
    opacity=0.95
):
    """
    Add multiple legend blocks stacked in ONE Leaflet corner overlay,
    with controllable x/y inset from the edge.
    """
    if not legend_html_blocks:
        return

    # Determine base anchors
    side = "right" if "right" in position else "left"
    vertical = "bottom" if "bottom" in position else "top"

    blocks = "\n".join(
        f"""
        <div style="
            margin-top: {gap_px}px;
            background: rgba(255,255,255,{opacity});
            border-radius: 8px;
            padding: 6px 8px;
            box-shadow: 0 1px 6px rgba(0,0,0,.15);
            max-width: {max_width_px}px;
            overflow: hidden;
        ">
            {html}
        </div>
        """
        for html in legend_html_blocks
    )

    tpl = Template(
        f"""
        {{% macro html(this, kwargs) %}}
        <div style="
            position: absolute;
            z-index: 9999;
            {side}: {inset_x_px}px;
            {vertical}: {inset_y_px}px;
            display: flex;
            flex-direction: column;
            align-items: stretch;
            pointer-events: none;
        ">
            {blocks}
        </div>
        {{% endmacro %}}
        """
    )

    macro = MacroElement()
    macro._template = tpl
    m.get_root().add_child(macro)

def shift_layer_control(
    m,
    *,
    position="bottomright",
    inset_x_px=80,     # horizontal shift toward center
    inset_y_px=120    # vertical shift upward
):
    """
    Move Leaflet LayerControl inward from the map edge,
    both horizontally and vertically.
    """
    side = "right" if "right" in position else "left"
    vertical = "bottom" if "bottom" in position else "top"

    css = f"""
    <style>
      .leaflet-control-layers.leaflet-control {{
          {side}: {inset_x_px}px !important;
          {vertical}: {inset_y_px}px !important;
      }}
    </style>
    """
    m.get_root().html.add_child(folium.Element(css))


def _nice_step_ticks(vmin: float, vmax: float, n: int = 6):
    """
    Create clean legend tick values without affecting the underlying colormap domain.
    Prefers integers when the range is >= ~10; otherwise uses 1 decimal.
    """
    if not np.isfinite(vmin) or not np.isfinite(vmax):
        return None
    if vmax <= vmin:
        return [vmin, vmin + 1.0]
    raw = np.linspace(vmin, vmax, n)
    span = vmax - vmin
    if span >= 10:
        ticks = [int(round(x)) for x in raw]
    else:
        ticks = [round(float(x), 1) for x in raw]
    # ensure strictly increasing (branca can be picky with duplicates)
    out = []
    last = None
    for x in ticks:
        if last is None or x > last:
            out.append(x)
            last = x
    if len(out) < 2:
        out = [vmin, vmax]
    return out


def export_edges_map(
    edges: pd.DataFrame,
    all_cells: Optional[pd.Index],
    title=None,
    *,
    edge_value_domain=None,   # (vmin, vmax) domain for EDGE colormap (optional)
    add_arrows=True,
    node_counts=None,
    node_intensity=None,
    hubs=None,
    metro_edges=None,
    metro_flows=None,
    metro_netflows=None,  # backward compat
    mean_node_accum=None,
    mean_node_layer_name="Mean node accumulation (in − out)",
    mean_node_show=False,
    outfile=None,
    edges_layer_name="Edges (general)",
    edges_show=True,
    metro_layer_name="Metro edges",
    metro_show=False,
    metro_fixed_width_px=3.0,
):
    """Render edges, hubs, and node overlays as a Folium map (LayerControl + stacked legends)."""
    if not HAS_FOLIUM:
        print("[MAP] Folium not available; skipping:", title)
        return
    if metro_flows is None and metro_netflows is not None:
        metro_flows = metro_netflows

    safe_title = "" if (title is None or title is Ellipsis) else str(title)

    # ----- center -----
    latlons = []
    if edges is not None and not edges.empty:
        latlons += edges[["src_lat", "src_lon"]].to_numpy().tolist()
        latlons += edges[["dst_lat", "dst_lon"]].to_numpy().tolist()
    if all_cells is not None and len(all_cells) > 0:
        latlons += [resolve_latlon(h) for h in all_cells]

    if latlons:
        lats = [p[0] for p in latlons]
        lons = [p[1] for p in latlons]
        center_lat, center_lon = float(np.mean(lats)), float(np.mean(lons))
    else:
        center_lat, center_lon = 19.4326, -99.1332

    m = folium.Map(location=[center_lat, center_lon], zoom_start=11, tiles=FOLIUM_TILES)
    if safe_title:
        add_title(m, safe_title, top_px=10)

    legend_blocks = []

    # ----- all cells -----
    if SHOW_ALL_CELLS and all_cells is not None and len(all_cells) > 0:
        fg_cells = folium.FeatureGroup(name="All cells (background)", show=False)
        for h in all_cells:
            lat, lon = resolve_latlon(h)
            folium.CircleMarker(
                location=(lat, lon),
                radius=ALL_CELLS_MARKER_RADIUS,
                color="#aaaaaa",
                fill=True, fill_color="#aaaaaa",
                fill_opacity=0.4, opacity=0.4,
                tooltip=h,
            ).add_to(fg_cells)
        fg_cells.add_to(m)

    # ----- overlay edges (from manifest) -----
    if MANIFEST_OVERLAY:
        fg_overlay = folium.FeatureGroup(name="Overlay edges (corridors/feeder)", show=True)
        for (s, d) in MANIFEST_OVERLAY:
            slat, slon = resolve_latlon(s)
            dlat, dlon = resolve_latlon(d)
            folium.PolyLine(
                [(slat, slon), (dlat, dlon)],
                color="#1f78b4",
                weight=2,
                opacity=0.65,
                tooltip=f"Overlay: {s} → {d}",
            ).add_to(fg_overlay)
        fg_overlay.add_to(m)

    # ----- background adjacency edges -----
    if MANIFEST_BACKGROUND:
        fg_bg = folium.FeatureGroup(name="Background adjacency edges", show=False)
        for (s, d) in MANIFEST_BACKGROUND:
            slat, slon = resolve_latlon(s)
            dlat, dlon = resolve_latlon(d)
            folium.PolyLine(
                [(slat, slon), (dlat, dlon)],
                color="#aaaaaa",
                weight=1,
                opacity=0.45,
                tooltip=f"Background: {s} → {d}",
            ).add_to(fg_bg)
        fg_bg.add_to(m)

    # ----- general edges -----
    if edges is not None and not edges.empty:
        vals = edges["count"].astype(float)

        if edge_value_domain is not None:
            evmin, evmax = float(edge_value_domain[0]), float(edge_value_domain[1])
        else:
            evmin, evmax = float(vals.min()), float(vals.max())

        if not np.isfinite(evmin):
            evmin = 0.0
        if not np.isfinite(evmax) or evmax <= evmin:
            evmax = evmin + 1.0

        cmap_edges = cmb.LinearColormap(
            ["#f5e6ff", "#9c27b0", "#4a0072"],
            vmin=evmin,
            vmax=evmax
        )

        ticks = _nice_step_ticks(evmin, evmax, n=6)
        if ticks:
            cmap_edges = cmap_edges.to_step(index=ticks)

        cmap_edges.caption = "Edge flow"

        fg_edges = folium.FeatureGroup(name=edges_layer_name, show=bool(edges_show))
        edges_sorted = edges.sort_values("count", ascending=True)

        for r in edges_sorted.itertuples(index=False):
            c = cmap_edges(float(r.count))
            folium.PolyLine(
                [[r.src_lat, r.src_lon], [r.dst_lat, r.dst_lon]],
                color=c, weight=1.6, opacity=0.75,
                tooltip=f"{r.src_h3} → {r.dst_h3}: {float(r.count):.1f}",
            ).add_to(fg_edges)
            if add_arrows and not getattr(r, "is_neutral", False):
                tri = _arrow_triangle(r.src_lat, r.src_lon, r.dst_lat, r.dst_lon)
                if tri:
                    folium.Polygon(
                        tri, color=c, fill=True, fill_color=c, fill_opacity=0.85
                    ).add_to(fg_edges)

        fg_edges.add_to(m)
        legend_blocks.append(cmap_edges._repr_html_())

    # ----- hubs -----
    if hubs:
        fg_hubs = folium.FeatureGroup(name="Hub nodes", show=True)
        for h in hubs:
            lat, lon = resolve_latlon(h)
            folium.CircleMarker(
                location=(lat, lon),
                radius=6, color="#ff0000", weight=2,
                fill=True, fill_color="#ff5555", fill_opacity=0.9,
                tooltip=f"Hub {h}",
            ).add_to(fg_hubs)
        fg_hubs.add_to(m)

    # ----- metro edges (hub↔hub) -----
    if metro_edges and (metro_flows or {}):
        flows_lookup = {
            (str(s).lower(), str(d).lower()): float(v)
            for (s, d), v in (metro_flows or {}).items()
        }
        if flows_lookup:
            m_vals = np.array(list(flows_lookup.values()), dtype=float)
            mvmin, mvmax = float(np.floor(m_vals.min())), float(np.ceil(m_vals.max()))
        else:
            mvmin = mvmax = 0.0

        cmap_metro = cmb.LinearColormap(
            colors=["#fff5e6", "#ff9900", "#b35900"], vmin=mvmin, vmax=mvmax
        )
        cmap_metro.caption = "Metro (Hub↔Hub) edge flow"

        fg_metro = folium.FeatureGroup(name=metro_layer_name, show=bool(metro_show))
        for (s, d) in metro_edges:
            s_key, d_key = str(s).lower(), str(d).lower()
            flow = flows_lookup.get((s_key, d_key))
            if flow is None or flow <= 0:
                continue
            slat, slon = resolve_latlon(s_key)
            dlat, dlon = resolve_latlon(d_key)
            color = cmap_metro(flow)
            folium.PolyLine(
                [[slat, slon], [dlat, dlon]],
                color=color,
                weight=float(metro_fixed_width_px),
                opacity=0.95,
                tooltip=f"Hub→Hub: {s_key} → {d_key}: {flow:.0f}",
            ).add_to(fg_metro)
            if add_arrows:
                tri = _arrow_triangle(slat, slon, dlat, dlon)
                if tri:
                    folium.Polygon(tri, color=color, fill=True, fill_color=color, fill_opacity=0.9).add_to(fg_metro)

        fg_metro.add_to(m)
        legend_blocks.append(cmap_metro._repr_html_())

    # ----- mean node accumulation -----
    if mean_node_accum:
        vals = np.array(list(mean_node_accum.values()), dtype=float)
        max_abs = float(np.max(np.abs(vals))) if vals.size else 1.0

        cmap_mean = cmb.LinearColormap(
            ["#2166ac", "#f7f7f7", "#b2182b"], vmin=-max_abs, vmax=max_abs
        )
        cmap_mean.caption = mean_node_layer_name

        fg_mean_nodes = folium.FeatureGroup(name=mean_node_layer_name, show=bool(mean_node_show))
        for h, acc in mean_node_accum.items():
            lat, lon = resolve_latlon(h)
            col = cmap_mean(float(acc))
            folium.CircleMarker(
                location=(lat, lon),
                radius=4, color="#000", weight=1,
                fill=True, fill_color=col, fill_opacity=0.9,
                tooltip=f"{h}: mean(in−out)={float(acc):.3f}",
            ).add_to(fg_mean_nodes)
        fg_mean_nodes.add_to(m)
        legend_blocks.append(cmap_mean._repr_html_())

    # ----- node intensity -----
    if node_intensity:
        vals = np.array(list(node_intensity.values()), dtype=float)
        vmin, vmax = float(vals.min()), float(vals.max())
        vmin_disp, vmax_disp = float(np.floor(vmin)), float(np.ceil(vmax))

        cmap_nodes = cmb.LinearColormap(
            ["#e3f2ff", "#73cfff", "#008dff", "#003b99"], vmin=vmin_disp, vmax=vmax_disp
        )
        cmap_nodes.caption = "Node intensity (start→end)"

        fg_nodes = folium.FeatureGroup(name="Node intensities (start counts)", show=True)
        for h, n0 in node_intensity.items():
            lat, lon = resolve_latlon(h)
            color = cmap_nodes(float(n0))
            nt_text = ""
            if node_counts and h in node_counts:
                n0_h, nt_h = node_counts[h]
                nt_text = f" → {int(nt_h)}"
                n0 = int(n0_h)

            folium.CircleMarker(
                location=(lat, lon),
                radius=3, color="#000000", weight=1,
                fill=True, fill_color=color, fill_opacity=0.9,
                tooltip=f"{h}: {int(round(n0))}{nt_text}",
            ).add_to(fg_nodes)
        fg_nodes.add_to(m)
        legend_blocks.append(cmap_nodes._repr_html_())

    # ---- Stacked legends (low z-index, never blocks clicks) ----
    add_stacked_legends(
        m,
        legend_blocks,
        position="bottomright",
        inset_x_px=200,    # pull legends toward center
        inset_y_px=140,    # move upward (key!)
        max_width_px=260,
        gap_px=8,
        opacity=0.92,
    )

    # ---- Layer control MUST be added LAST ----
    folium.LayerControl(
        collapsed=False,
        position="bottomright"
    ).add_to(m)

    shift_layer_control(
        m,
        position="bottomright",
        inset_x_px=200,     # toward center horizontally
        inset_y_px=500      # upward → visually centered
    )

    if outfile:
        m.save(outfile)
        print(f"[MAP] wrote {outfile}")


# =========================
# Mean/flow helpers
# =========================
def compute_mean_direct(per_bin):
    N = per_bin[0].F.shape[0]
    S = sparse.csr_matrix((N, N))
    for pb in per_bin:
        S = S + pb.F
    return S.toarray() / max(1, len(per_bin))

def split_inward_outward_complement(meanF, tol):
    N = meanF.shape[0]
    F_in = np.zeros((N, N))
    F_out = np.zeros((N, N))
    F_neu = np.zeros((N, N))
    for i in range(N):
        for j in range(i+1, N):
            a = meanF[i, j]; b = meanF[j, i]
            if abs(a - b) <= tol:
                w = 0.5 * (a + b)
                F_neu[i, j] = w; F_neu[j, i] = w
            elif a > b:
                F_in[i, j] = a
                F_out[j, i] = b
            else:
                F_in[j, i] = b
                F_out[i, j] = a
    return F_in, F_out, F_neu

def compute_mean_node_accumulation(per_bin, i1, i2_excl):
    N = per_bin[0].F.shape[0]
    nb = max(1, i2_excl - i1)
    sum_in = np.zeros(N)
    sum_out = np.zeros(N)
    sum_d = np.zeros(N)
    for t in range(i1, i2_excl):
        F = per_bin[t].F
        inflow = np.asarray(F.sum(axis=1)).ravel()
        outflow = np.asarray(F.sum(axis=0)).ravel()
        sum_in += inflow; sum_out += outflow; sum_d += (inflow - outflow)
    return sum_in/nb, sum_out/nb, sum_d/nb


# =========================
# Main
# =========================
def main():
    print("[SETUP] OUTPUT_DIR:", OUTPUT_DIR)
    print("[MANIFEST] entries:", len(MANIFEST_NODES))

    # Load full manifest as raw dict for delta_T access
    with open(CORRIDOR_MANIFEST_PATH, "r") as f:
        _doc = json.load(f)

    print(f"[READ] {OD_INPUT_PATH}")
    raw = pd.read_csv(OD_INPUT_PATH, dtype={START_COL: str, END_COL: str})
    od = crop_to_span_STRICT(raw, SPAN_START, SPAN_END, TIME_RES_MIN)
    if od.empty:
        raise RuntimeError("No rows in span.")

    per_bin, cells = build_per_bin(od)
    i1, i2_excl, t1, t2 = locate_span(per_bin, SPAN_START, SPAN_END, TIME_RES_MIN)

    from_slug = t1.strftime("%Y%m%d_%H%M")
    to_slug = t2.strftime("%Y%m%d_%H%M")

    # --- Netflows ---
    if RUN_NETFLOWS:
        C = legacy_elapsed_counts(per_bin, i1, i2_excl)
        n0 = np.asarray(per_bin[i1].F.sum(axis=0)).ravel().astype(int)
        nt = np.asarray(C.sum(axis=1)).ravel().astype(int)
        node_counts = {cells[k]: (int(n0[k]), int(nt[k])) for k in range(len(cells))}
        node_intensity = {cells[k]: int(n0[k]) for k in range(len(cells))}

        Cnet = C - C.T
        if DROP_DIAGONAL:
            np.fill_diagonal(Cnet, 0.0)
        Cnet = np.maximum(Cnet, 0.0)

        # ===== FIX: compute domain from UNFILTERED Cnet, not from edges_net =====
        # global max should NOT depend on NETFLOWS_PERCENTILE
        GLOBAL_NETFLOW_MAX = float(Cnet.max()) if Cnet.size else 0.0

        # vmin should reflect the visibility threshold (percentile + MIN_COUNT), not 0
        positive_vals = Cnet[Cnet > 0]
        if positive_vals.size > 0 and NETFLOWS_PERCENTILE > 0:
            NETFLOW_THR = float(np.quantile(positive_vals, NETFLOWS_PERCENTILE))
        else:
            NETFLOW_THR = 0.0
        NETFLOW_VMIN = float(max(NETFLOW_THR, MIN_COUNT))

        metro_netflows = {}
        if MANIFEST_METRO_EDGES and SHOW_METRO_EDGES:
            gh_to_idx = {str(g).lower(): i for i, g in enumerate(cells)}
            for (s, d) in MANIFEST_METRO_EDGES:
                s_key, d_key = str(s).lower(), str(d).lower()
                isrc, idst = gh_to_idx.get(s_key), gh_to_idx.get(d_key)
                if isrc is None or idst is None:
                    continue
                val = float(Cnet[idst, isrc])
                if val > 0:
                    metro_netflows[(s_key, d_key)] = val

        edges_net = counts_to_edges(Cnet, cells, NETFLOWS_PERCENTILE, MIN_COUNT)

        if MAKE_MAPS:
            html_net = os.path.join(
                OUTPUT_DIR,
                f"netflows_map_h3r{H3_RES}_p{int(round(NETFLOWS_PERCENTILE*100))}_{from_slug}_to_{to_slug}.html"
            )
            export_edges_map(
                edges_net, cells,
                title=f"Net flows  — Top {int(round(100 - NETFLOWS_PERCENTILE * 100))}% —  (H3 r{H3_RES}) — {t1:%Y-%m-%d %H:%M} → {t2:%Y-%m-%d %H:%M}",
                node_counts=node_counts,
                node_intensity=(node_intensity if SHOW_NODE_INTENSITY else None),
                hubs=MANIFEST_HUBS,
                metro_edges=MANIFEST_METRO_EDGES,
                metro_flows=metro_netflows,
                outfile=html_net,
                edges_layer_name="Netflow edges",
                edges_show=True,
                metro_layer_name="Metro edges (netflows)",
                metro_show=False,
                # ===== FIX: enforce correct edge colorbar domain =====
                edge_value_domain=(NETFLOW_VMIN, GLOBAL_NETFLOW_MAX),
            )

    # ============================================================
    # === MEAN EDGE FLOW MAPS (δT = +1, −1, and ΔT = 0 case) ======
    # ============================================================

    if RUN_MEAN_EDGE_IN_OUT:

        print("[MEAN] Computing mean direct flows...")
        meanF = compute_mean_direct(per_bin)

        # ============================================================
        # Build directional edge sets from manifest (NOT from meanF)
        # ============================================================
        records = []
        for rec in _doc.get("edges", {}).get("AM", []):
            if int(rec.get("is_metro", 0)) == 1:
                continue
            try:
                s = str(rec["start_h3"]).lower()
                d = str(rec["end_h3"]).lower()
                delta_T = int(rec.get("delta_T"))
            except Exception:
                continue
            records.append({"start_h3": s, "end_h3": d, "delta_T": delta_T})

        manifest_df = pd.DataFrame(records)

        # Correct directional grouping
        edges_dt_pos  = {(r.start_h3, r.end_h3) for r in manifest_df.itertuples() if r.delta_T == 1}
        edges_dt_neg  = {(r.start_h3, r.end_h3) for r in manifest_df.itertuples() if r.delta_T == -1}
        edges_dt_zero = {(r.start_h3, r.end_h3) for r in manifest_df.itertuples() if r.delta_T == 0}

        # ============================
        # Split METRO edges by delta_T
        # ============================
        metro_dt_pos  = set()
        metro_dt_neg  = set()
        metro_dt_zero = set()

        for rec in _doc.get("edges", {}).get("AM", []):
            try:
                if int(rec.get("is_metro", 0)) != 1:
                    continue
                s = str(rec["start_h3"]).lower()
                d = str(rec["end_h3"]).lower()
                dt = int(rec.get("delta_T"))
            except Exception:
                continue

            if dt == 1:
                metro_dt_pos.add((s, d))
            elif dt == -1:
                metro_dt_neg.add((s, d))
            else:
                metro_dt_zero.add((s, d))

        # ============================================================
        # Now attach mean-flow weights to ONLY those edges
        # ============================================================

        idx_of = {h: i for i, h in enumerate(cells)}

        def _build_df_from_manifest_edge_set(edge_set):
            rows = []
            for (s, d) in edge_set:
                si = idx_of.get(s); di = idx_of.get(d)
                if si is None or di is None:
                    continue
                val = float(meanF[di, si])   # mean flow from s→d
                if val <= 0:
                    continue
                slat, slon = resolve_latlon(s)
                dlat, dlon = resolve_latlon(d)
                rows.append({
                    "src_h3": s, "dst_h3": d,
                    "src_lat": slat, "src_lon": slon,
                    "dst_lat": dlat, "dst_lon": dlon,
                    "count": val
                })
            df = pd.DataFrame(rows)
            if not df.empty:
                df.sort_values("count", ascending=False, inplace=True)
            return df

        # Build directional DF
        df_inward  = _build_df_from_manifest_edge_set(edges_dt_pos  | edges_dt_zero)
        df_outward = _build_df_from_manifest_edge_set(edges_dt_neg  | edges_dt_zero)

        # Debug CSVs
        df_inward.to_csv(os.path.join(OUTPUT_DIR, "mean_inward_edges.csv"), index=False)
        df_outward.to_csv(os.path.join(OUTPUT_DIR, "mean_outward_edges.csv"), index=False)
        print("[MEAN] Wrote mean_inward_edges.csv and mean_outward_edges.csv")

        # ============================
        # Metro mean flows (split by delta_T)
        # ============================
        idx_of = {h: i for i, h in enumerate(cells)}

        def build_metro_mean(edge_set):
            out = {}
            for (s, d) in edge_set:
                si = idx_of.get(s)
                di = idx_of.get(d)
                if si is None or di is None:
                    continue
                val = float(meanF[di, si])
                if val > 0:
                    out[(s, d)] = val
            return out

        metro_mean_in  = build_metro_mean(metro_dt_pos  | metro_dt_zero)
        metro_mean_out = build_metro_mean(metro_dt_neg  | metro_dt_zero)

        # ---------------------------
        # δT = +1 (inward)
        # ---------------------------
        html_in = os.path.join(
            OUTPUT_DIR,
            f"meanflow_inward_h3r{H3_RES}_{from_slug}_to_{to_slug}.html"
        )
        export_edges_map(
            df_inward, cells,
            title=f"Edge flow (δT = +1, inward) — {t1:%Y-%m-%d %H:%M} → {t2:%Y-%m-%d %H:%M}",
            hubs=MANIFEST_HUBS,
            metro_edges=list(metro_dt_pos | metro_dt_zero),
            metro_flows=metro_mean_in,
            edges_layer_name="Mean inward edges",
            edges_show=True,
            metro_layer_name="Metro (mean flows)",
            metro_show=False,
            outfile=html_in,
        )

        # ---------------------------
        # δT = −1 (outward)
        # ---------------------------
        html_out = os.path.join(
            OUTPUT_DIR,
            f"meanflow_outward_h3r{H3_RES}_{from_slug}_to_{to_slug}.html"
        )
        export_edges_map(
            df_outward, cells,
            title=f"Mean edge flows (δT = −1, outward) — {t1:%Y-%m-%d %H:%M} → {t2:%Y-%m-%d %H:%M}",
            hubs=MANIFEST_HUBS,
            metro_edges=list(metro_dt_neg | metro_dt_zero),
            metro_flows=metro_mean_out,
            edges_layer_name="Mean outward edges",
            edges_show=True,
            metro_layer_name="Metro (mean flows)",
            metro_show=False,
            outfile=html_out,
        )

        print("[MEAN] Mean flow maps written.")

    print("[DONE]")


if __name__ == "__main__":
    main()
